{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5399d949",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2e71ace-9806-4ca0-a374-06821124cdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run focalloss.ipynb\n",
    "%run mfeloss.ipynb\n",
    "%run msfeloss.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4652e518",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "\n",
    "class NeuralN(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dimension = None, output_dimension = None, hidden_layers=None, num_hidden_layers = None, hidden_dim = 64,\n",
    "                 activation_default = \"relu\", threshold = 0.3,\n",
    "                 activations = None, loss_method = \"BCE\", opt_method = \"SGD\", lr = 0.01, class_weights = None, alpha=None, data_type = None, gamma = None, epochs=None):\n",
    "        \n",
    "        super().__init__() \n",
    "        \n",
    "        self.loss_method = loss_method\n",
    "        self.opt_method = opt_method\n",
    "        self.lr = lr \n",
    "        self.alpha = alpha \n",
    "        self.gamma = gamma \n",
    "        self.epochs = epochs\n",
    "        self.input_dimension = input_dimension \n",
    "        self.output_dimension = output_dimension\n",
    "        self.hidden_layers = hidden_layers #list\n",
    "        self.num_hidden_layers = num_hidden_layers\n",
    "        self.hidden_dim = hidden_dim #default\n",
    "        self.activation_default = activation_default #default \n",
    "        self.activations = activations #list\n",
    "        self.data_type = data_type\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        if class_weights is not None:\n",
    "            self.class_weights = torch.tensor([class_weights[1], class_weights[0]], dtype= torch.float32)\n",
    "        else: \n",
    "            self.class_weights = class_weights\n",
    "        \n",
    "        self.process = nn.ModuleList()\n",
    "\n",
    "        layer = None\n",
    "        if self.hidden_layers is not None:\n",
    "            \n",
    "            layer = [self.input_dimension] + self.hidden_layers + [self.output_dimension]\n",
    "\n",
    "        else: \n",
    "\n",
    "            layer = [self.input_dimension] + [self.hidden_dim]*self.num_hidden_layers + [self.output_dimension]\n",
    "\n",
    "        act = None\n",
    "        if self.activations is not None:\n",
    "            \n",
    "            if len(self.activations) < (len(layer)):\n",
    "                need = (len(layer)) - len(self.activations)\n",
    "                act = self.activations + [\"identity\"]*need #Could be self.activation[0] or desired activation function. \n",
    "            \n",
    "            else: \n",
    "                act = self.activations\n",
    "\n",
    "        else: \n",
    "\n",
    "            act = [self.activation_default]* (len(layer) - 1) \n",
    "\n",
    "        for i in range(1, len(layer)):\n",
    "            self.process.append(nn.Linear(layer[i-1], layer[i]))\n",
    "            \n",
    "            if i < (len(layer) - 1):\n",
    "                self.process.append(self.get_activation(act[i-1]))\n",
    "            \n",
    "            elif i == (len(layer) - 1):\n",
    "\n",
    "                if self.loss_method == \"BCE\": \n",
    "                    self.process.append(nn.Sigmoid())\n",
    "\n",
    "                else: \n",
    "                    self.process.append(nn.Identity())\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        #https://medium.com/data-scientists-diary/advanced-guide-to-using-nn-modulelist-in-pytorch-da4d49c109fc\n",
    "        x = x.float()\n",
    "        for m in self.process:\n",
    "            x = m(x)\n",
    "        return x\n",
    "\n",
    "    def get_activation(self, activation_):\n",
    "\n",
    "        if activation_ == \"relu\": \n",
    "            return nn.ReLU()\n",
    "\n",
    "        elif activation_ == \"tanh\": \n",
    "            return nn.Tanh()\n",
    "\n",
    "        elif activation_ == \"identity\": \n",
    "            return nn.Identity()\n",
    "        \n",
    "    def get_loss(self):\n",
    "        \n",
    "        \n",
    "        if self.loss_method == \"BCE\":\n",
    "            return nn.BCELoss()\n",
    "        \n",
    "        elif self.loss_method == \"L1\":\n",
    "            return nn.L1Loss()\n",
    "        \n",
    "        elif self.loss_method == \"MSE\":\n",
    "            return nn.MSELoss()\n",
    "\n",
    "        elif self.loss_method == \"CE\":\n",
    "            return nn.CrossEntropyLoss(weight = self.class_weights)\n",
    "\n",
    "        elif self.loss_method == \"BCEwLogit\":\n",
    "            if self.class_weights is not None:\n",
    "                pos_weight = torch.tensor([self.class_weights[1] / self.class_weights[0]])\n",
    "                return nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n",
    "            else: \n",
    "                return nn.BCEWithLogitsLoss()\n",
    "\n",
    "        elif self.loss_method == \"focal_loss\": #https://medium.com/visionwizard/understanding-focal-loss-a-quick-read-b914422913e7\n",
    "            return FocalLoss(alpha=self.alpha, gamma=self.gamma)\n",
    "\n",
    "        elif self.loss_method == \"MFE\":\n",
    "            return MFELoss()\n",
    "\n",
    "        elif self.loss_method == \"MSFE\":\n",
    "            return MSFELoss()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"{self.loss_method} is not valid!\")\n",
    "    \n",
    "    def get_optimizer(self):\n",
    "        \n",
    "        if self.opt_method == \"SGD\":\n",
    "            return torch.optim.SGD(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        elif self.opt_method == \"Adam\":\n",
    "            return torch.optim.Adam(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        elif self.opt_method == \"RMSprop\":\n",
    "            return torch.optim.RMSprop(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        else: \n",
    "            raise ValueError(f\"{self.opt_method} is not valid!\")\n",
    "    \n",
    "    def train_model(self, train_loader, val_loader, optimizer=None, loss_fn=None):#https://www.geeksforgeeks.org/how-to-implement-neural-networks-in-pytorch/\n",
    "\n",
    "        loss_fn = self.get_loss()\n",
    "        optimizer = self.get_optimizer()        \n",
    "        size = len(train_loader.dataset)\n",
    "        t_loss=[]\n",
    "        val_loss = []\n",
    "        for e in range(self.epochs):\n",
    "            self.train()\n",
    "            train_loss = 0\n",
    "            for batch, (X, y) in enumerate(train_loader):\n",
    "                \n",
    "                y_logits = self(X).squeeze()\n",
    "                \n",
    "                loss = loss_fn(y_logits, y)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                train_loss += loss.item() * X.size(0)\n",
    "            train_loss_ = train_loss/len(train_loader.dataset) \n",
    "            t_loss.append(train_loss_)\n",
    "            \n",
    "            self.eval()\n",
    "            test_loss = 0\n",
    "            with torch.inference_mode():\n",
    "                for X, y in val_loader: \n",
    "                    \n",
    "                    y_logits = self(X).squeeze()\n",
    "                    test_loss += loss_fn(y_logits, y).item() * y.size(0)\n",
    "                \n",
    "        \n",
    "            test_loss_ = test_loss/len(val_loader.dataset)\n",
    "            val_loss.append(test_loss_)\n",
    "    \n",
    "        return t_loss, val_loss\n",
    "        \n",
    "            #https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html\n",
    "        \n",
    "    #https://flock-io.medium.com/credit-card-fraud-detection-build-your-own-model-part-1-9b6cac3c991c\n",
    "    #https://discuss.pytorch.org/t/correct-way-to-calculate-train-and-valid-loss/178974 --> For loss visualization\n",
    "    def test_model(self, test_loader, loss_fn=None):\n",
    "        \n",
    "        loss_fn = self.get_loss()\n",
    "        val_loss = []\n",
    "\n",
    "        for e in range(self.epochs): \n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    " \n",
    "                \n",
    "                test_loss = 0\n",
    "                for X, y in test_loader: \n",
    "                    y_logits = self(X).squeeze()\n",
    "                    test_loss += loss_fn(y_logits, y).item() * y.size(0)\n",
    "                    \n",
    "                test_loss_ = test_loss/len(test_loader.dataset)\n",
    "                val_loss.append(test_loss_)\n",
    "        return val_loss\n",
    "\n",
    "    def store(self, operation=None, path = None): #https://pytorch.org/tutorials/beginner/saving_loading_models.html\n",
    "    \n",
    "        if operation == \"save\": \n",
    "            torch.save(self.state_dict(), path)\n",
    "    \n",
    "        elif operation == \"load\": \n",
    "            self.load_state_dict(torch.load(path, weights_only = True))\n",
    "            print(\"Loading successfull ! \")\n",
    "\n",
    "    def analysis(self, l1, l2):\n",
    "        #https://www.geeksforgeeks.org/how-to-create-a-multiline-plot-using-seaborn/\n",
    "        l1_arr = np.array(l1)\n",
    "        l2_arr = np.array(l2)\n",
    "\n",
    "        epoch_l = [i for i in range(1, self.epochs + 1)]\n",
    "        epoch_arr = np.array(epoch_l)\n",
    "\n",
    "        sns.lineplot(x = epoch_arr, y = l1_arr, label=\"Train Error\")\n",
    "        sns.lineplot(x = epoch_arr, y = l2_arr, label=\"Valid Error\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def predict(self, test):\n",
    "    #https://discuss.pytorch.org/t/how-to-use-pytorch-to-output-the-probability-of-binary-classfication/101043/2\n",
    "    #https://codesignal.com/learn/courses/building-a-neural-network-in-pytorch/lessons/making-predictions-with-a-trained-pytorch-model\n",
    "    #https://discuss.pytorch.org/t/how-to-make-pytorch-model-predict/167950\n",
    "        predictions=[]\n",
    "        labels = []\n",
    "        probs=[]\n",
    "        if self.loss_method == \"BCE\": \n",
    "            \n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    \n",
    "                    output = self(X).squeeze()\n",
    "                    preds = (output > self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(output)\n",
    "                    \n",
    "        elif self.loss_method == \"CE\": \n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    output = self(X).squeeze()\n",
    "                    prob = torch.argmax(output, dim=1)\n",
    "                    preds = (prob>self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(prob)\n",
    "                    \n",
    "        else:\n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    output = self(X).squeeze()\n",
    "                    prob = torch.sigmoid(output)\n",
    "                    preds = (prob > self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(prob)\n",
    "\n",
    "        all_preds = torch.cat(predictions).ravel()\n",
    "        all_labels = torch.cat(labels).ravel()\n",
    "        all_probs = torch.cat(probs).ravel()\n",
    "        \n",
    "        return all_probs, all_preds, all_labels\n",
    "        \n",
    "    def report(self, test, pred, labels): \n",
    "\n",
    "        all_probs, all_preds, all_labels = self.predict(test)\n",
    "        all_probs_arr = all_probs.detach().numpy().ravel()\n",
    "        all_preds_arr = all_preds.detach().numpy().ravel()\n",
    "        all_labels_arr = all_labels.detach().numpy().ravel()\n",
    "        \n",
    "        cm = confusion_matrix(all_labels_arr, all_preds_arr)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.ylabel(\"Actual Class\")\n",
    "        plt.xlabel(\"Predicted Class\")\n",
    "\n",
    "        plt.show()\n",
    "            \n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
