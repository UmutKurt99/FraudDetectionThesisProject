{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf83de9-5773-45fe-ab40-e03c34c65a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn import metrics\n",
    "import seaborn as sns\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7c0bafb-16c7-40ba-9471-36a0893be413",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionNN(nn.Module):\n",
    "\n",
    "    def __init__(self, loss_method = \"BCE\", opt_method = \"SGD\", lr = 0.01, threshold = 0.3, class_weights = None, epochs=5, input_dimension = None, dropout_list=None, linear_act = None, flattened_size = None, linear_layer = None, layer_list = None,default_layer=None, pool_counts=None, activation_count=None, pool=None, activations=None, layer_count = None, dropout_count = None, dropout_rate= None, layer_default = 30, output_dimension= None, kernel = 3, padding=1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_dimension = input_dimension\n",
    "        self.output_dimension = output_dimension\n",
    "        self.kernel = kernel\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.dropout_count = dropout_count\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.layer_list = layer_list\n",
    "        self.dropout_rate = dropout_rate\n",
    "        self.dropout_list = dropout_list\n",
    "        self.dropout_count = dropout_count\n",
    "        self.pool_counts = pool_counts\n",
    "        self.pool = pool\n",
    "        self.layer_count = layer_count\n",
    "        self.activations = activations\n",
    "        self.activation_count = activation_count\n",
    "        self.layer_default = layer_default\n",
    "        self.default_layer = default_layer\n",
    "        self.linear_layer = linear_layer\n",
    "        self.flattened_size = flattened_size\n",
    "        self.loss_method = loss_method\n",
    "        self.opt_method = opt_method\n",
    "        self.lr = lr \n",
    "        self.class_weights = class_weights\n",
    "        self.epochs = epochs\n",
    "        self.threshold = threshold\n",
    "        \n",
    "        if self.class_weights is not None:\n",
    "            self.class_weights = torch.tensor([class_weights[1], class_weights[0]], dtype= torch.float32)\n",
    "        else: \n",
    "            self.class_weights = class_weights\n",
    "            \n",
    "        layer_dict = {}\n",
    "        \n",
    "        if self.layer_list is None: \n",
    "            \n",
    "            layer = [self.input_dimension] + [self.default_layer]*self.layer_count + [self.output_dimension]\n",
    "\n",
    "        else: \n",
    "            \n",
    "            layer = self.layer_list\n",
    "\n",
    "        for i in range(1, len(layer)):\n",
    "\n",
    "            layer_dict[f\"conv{i}\"] = nn.Conv1d(layer[i-1], layer[i], kernel_size = self.kernel, padding = self.padding)\n",
    "\n",
    "            act = None\n",
    "            if self.activations is None:\n",
    "                \n",
    "                layer_dict[f\"act{i-1}\"] = nn.ReLU()\n",
    "\n",
    "            else: \n",
    "\n",
    "                if len(self.activations) < (len(layer)):\n",
    "                    need_act = (len(layer)) - len(self.activations)\n",
    "                    act = self.activations + [\"identity\"]*need_act \n",
    "                    \n",
    "                layer_dict[f\"act{i-1}\"] = self.get_activation(act[i-1])\n",
    "\n",
    "            pooling = None            \n",
    "            if self.pool is None:\n",
    "                \n",
    "                layer_dict[f\"pooling{i-1}\"] = nn.MaxPool1d(2,2)\n",
    "\n",
    "            else: \n",
    "                \n",
    "                if len(self.pool) < (len(layer)):\n",
    "                    need_pool = (len(layer)) - len(self.pool)\n",
    "                    pooling = self.pool + [2]*need_pool\n",
    "                layer_dict[f\"pooling{i-1}\"] = nn.MaxPool1d(pooling[i-1], pooling[i])\n",
    "\n",
    "            drop = None\n",
    "            if self.dropout_list is None: \n",
    "                \n",
    "                layer_dict[f\"dropout{i-1}\"] = nn.Dropout(self.dropout_rate)\n",
    "\n",
    "            else: \n",
    "                if len(self.dropout_list) < (len(layer)):\n",
    "                    need_drop = (len(layer)) - len(self.dropout_list)\n",
    "                    drop = self.dropout_list + [0.3]*need_drop \n",
    "                layer_dict[f\"dropout{i-1}\"] = nn.Dropout(drop[i-1])\n",
    "\n",
    "    \n",
    "        \n",
    "        self.linear1 = nn.Linear(self.flattened_size, self.linear_layer)\n",
    "        self.linear2 = nn.Linear(self.linear_layer, self.output_dimension)\n",
    "\n",
    "        self.process = nn.ModuleDict(layer_dict)\n",
    "        print(self.process)\n",
    "    \n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        for m in self.process.values():\n",
    "            x = m(x)\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = F.relu(self.linear1(x))\n",
    "        x = F.relu(self.linear2(x))\n",
    "        \n",
    "        print(x)\n",
    "        return x\n",
    "        \n",
    "    def get_activation(self, activation_):\n",
    "\n",
    "        if activation_ == \"relu\": \n",
    "            return nn.ReLU()\n",
    "\n",
    "        elif activation_ == \"tanh\": \n",
    "            return nn.Tanh()\n",
    "\n",
    "        elif activation_ == \"identity\": \n",
    "            return nn.Identity()\n",
    "\n",
    "    def get_loss(self):\n",
    "        \n",
    "        \n",
    "        if self.loss_method == \"BCE\":\n",
    "            return nn.BCELoss()\n",
    "        \n",
    "        elif self.loss_method == \"L1\":\n",
    "            return nn.L1Loss()\n",
    "        \n",
    "        elif self.loss_method == \"MSE\":\n",
    "            return nn.MSELoss()\n",
    "\n",
    "        elif self.loss_method == \"CE\":\n",
    "            return nn.CrossEntropyLoss(weight = self.class_weights)\n",
    "\n",
    "        elif self.loss_method == \"BCEwLogit\":\n",
    "            if self.class_weights is not None:\n",
    "                pos_weight = torch.tensor([self.class_weights[1] / self.class_weights[0]])\n",
    "                return nn.BCEWithLogitsLoss(pos_weight = pos_weight)\n",
    "            else: \n",
    "                return nn.BCEWithLogitsLoss()\n",
    "\n",
    "        else:\n",
    "            raise ValueError(f\"{self.loss_method} is not valid!\")\n",
    "\n",
    "    def get_optimizer(self):\n",
    "        \n",
    "        if self.opt_method == \"SGD\":\n",
    "            return torch.optim.SGD(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        elif self.opt_method == \"Adam\":\n",
    "            return torch.optim.Adam(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        elif self.opt_method == \"RMSprop\":\n",
    "            return torch.optim.RMSprop(params = self.parameters(), lr = self.lr)\n",
    "\n",
    "        else: \n",
    "            raise ValueError(f\"{self.opt_method} is not valid!\")\n",
    "\n",
    "    def train_model(self, train_loader, optimizer=None, loss_fn=None):#https://www.geeksforgeeks.org/how-to-implement-neural-networks-in-pytorch/\n",
    "\n",
    "        loss_fn = self.get_loss()\n",
    "        optimizer = self.get_optimizer()        \n",
    "        size = len(train_loader.dataset)\n",
    "        t_loss=[]\n",
    "        for e in range(self.epochs):\n",
    "            self.train()\n",
    "            train_loss = 0\n",
    "            for batch, (X, y) in enumerate(train_loader):\n",
    "                X = X.unsqueeze(1)\n",
    "                y_logits = self(X).squeeze()\n",
    "                \n",
    "                loss = loss_fn(y_logits, y)\n",
    "    \n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "    \n",
    "                train_loss += loss.item() * X.size(0)\n",
    "    \n",
    "            train_loss_ = train_loss/len(train_loader.dataset) \n",
    "            t_loss.append(train_loss_)\n",
    "        return t_loss\n",
    "\n",
    "    def test_model(self, test_loader, loss_fn=None):\n",
    "        loss_fn = self.get_loss()\n",
    "        self.eval()\n",
    "        \n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            val_loss = []\n",
    "            for e in range(self.epochs):\n",
    "                test_loss = 0\n",
    "                for X, y in test_loader: \n",
    "                    X = X.unsqueeze(1)\n",
    "                    y_logits = self(X).squeeze()\n",
    "                    test_loss += loss_fn(y_logits, y).item() * y.size(0)\n",
    "                    \n",
    "                test_loss_ = test_loss/len(test_loader.dataset)\n",
    "                val_loss.append(test_loss_)\n",
    "            return val_loss\n",
    "\n",
    "    def analysis(self, l1, l2):\n",
    "        #https://www.geeksforgeeks.org/how-to-create-a-multiline-plot-using-seaborn/\n",
    "        l1_arr = np.array(l1)\n",
    "        l2_arr = np.array(l2)\n",
    "\n",
    "        epoch_l = [i for i in range(1, self.epochs + 1)]\n",
    "        epoch_arr = np.array(epoch_l)\n",
    "\n",
    "        sns.lineplot(x = epoch_arr, y = np.log(l1_arr), label=\"Train Error\")\n",
    "        sns.lineplot(x = epoch_arr, y = np.log(l2_arr), label=\"Valid Error\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "    def predict(self, test):\n",
    "    #https://discuss.pytorch.org/t/how-to-use-pytorch-to-output-the-probability-of-binary-classfication/101043/2\n",
    "    #https://codesignal.com/learn/courses/building-a-neural-network-in-pytorch/lessons/making-predictions-with-a-trained-pytorch-model\n",
    "    #https://discuss.pytorch.org/t/how-to-make-pytorch-model-predict/167950\n",
    "        predictions=[]\n",
    "        labels = []\n",
    "        probs=[]\n",
    "        if self.loss_method == \"BCE\": \n",
    "            \n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    X = X.unsqueeze(1)\n",
    "                    output = self(X).squeeze()\n",
    "                    preds = (output > self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(output)\n",
    "                    \n",
    "        elif self.loss_method == \"CE\": \n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    X = X.unsqueeze(1)\n",
    "                    output = self(X)\n",
    "                    prob = torch.argmax(output, dim=1)\n",
    "                    preds = (prob>self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(prob)\n",
    "                    \n",
    "        else:\n",
    "            self.eval()\n",
    "            with torch.inference_mode():\n",
    "                for X, y in test:\n",
    "                    X = X.unsqueeze(1)\n",
    "                    output = self(X).squeeze()\n",
    "                    prob = torch.sigmoid(output)\n",
    "                    preds = (prob > self.threshold).int()\n",
    "                    predictions.append(preds)\n",
    "                    labels.append(y)\n",
    "                    probs.append(prob)\n",
    "\n",
    "        all_preds = torch.cat(predictions).ravel()\n",
    "        all_labels = torch.cat(labels).ravel()\n",
    "        all_probs = torch.cat(probs).ravel()\n",
    "        \n",
    "        return all_probs, all_preds, all_labels\n",
    "        \n",
    "    def report(self, test, pred, labels): \n",
    "\n",
    "        all_probs, all_preds, all_labels = self.predict(test)\n",
    "        all_probs_arr = all_probs.detach().numpy().ravel()\n",
    "        all_preds_arr = all_preds.detach().numpy().ravel()\n",
    "        all_labels_arr = all_labels.detach().numpy().ravel()\n",
    "        \n",
    "        cm = confusion_matrix(all_labels_arr, all_preds_arr)\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "        plt.title(\"Confusion Matrix\")\n",
    "        plt.ylabel(\"Actual Class\")\n",
    "        plt.xlabel(\"Predicted Class\")\n",
    "\n",
    "        plt.show()\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
